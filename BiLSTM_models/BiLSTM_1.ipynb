{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/opt/conda/bin/python3.7 -m pip install --upgrade pip\n",
    "!pip install seqeval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Deep learning NER con bilstm y crf - model-04-tfa-fastText-(Scielo+wiki-uncased-cbow)+(char-50)\n",
    "\n",
    "### Definicion de Parametro e Hiperparametros del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/libsutils')\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from itertools import islice\n",
    "\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report as eskclarep\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from seqeval.metrics import classification_report as seqclarep\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from itertools import chain\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Concatenate, Lambda, Input, LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, InputLayer, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam, schedules\n",
    "from crfta import CRF as crf4\n",
    "from utils import build_matrix_embeddings as bme, plot_model_performance, logits_to_tokens, report_to_df\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import datetime, os\n",
    "import random\n",
    "\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'  # TF 2.1+\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "MODEL         = 'model-04-tfa-fastText-(Scielo+wiki-cased-cbow)+(char-50)'\n",
    "logs_base_dir = \"./logs\"\n",
    "log_dir       = logs_base_dir + \"/\" + MODEL\n",
    "save_base_dir = './model-save'\n",
    "save_dir      = save_base_dir + \"/\" + MODEL\n",
    "\n",
    "os.makedirs(logs_base_dir, exist_ok=True)\n",
    "os.makedirs(log_dir,       exist_ok=True)\n",
    "os.makedirs(save_base_dir, exist_ok=True)\n",
    "os.makedirs(save_dir,      exist_ok=True)\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "# ****** DEFINICION DE PARAMETROS *********\n",
    "\n",
    "#NUM_WORDS   = 12154 + 2\n",
    "#LEN_SENTS   = 153\n",
    "#NUM_TAGS    = 19 + 2\n",
    "\n",
    "NUM_WORDS   = 12071 + 2\n",
    "LEN_SENTS   = 153\n",
    "NUM_TAGS    = 30 + 2\n",
    "\n",
    "# ****** DEFINICION DE HIPERPARAMETROS *********\n",
    "_EPOCHS      = 50 #50\n",
    "EMBED_DIM    = 300\n",
    "CHAR_EMBEDD  = 50\n",
    "_DROPOUT     = 0.5\n",
    "REC_DROPOUT  = 0.1\n",
    "LEARN_RATE   = 1e-3\n",
    "N_TRAIN      = int(1e4)\n",
    "EP_DECAY     = 1e-8\n",
    "BETA_1       = 0.9\n",
    "BETA_2       = 0.999\n",
    "_BACH_SIZE   = 500\n",
    "VAL_SPLIT    = 0.1\n",
    "STEPS_PER_EPOCH = N_TRAIN//_BACH_SIZE\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            \n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "path_vectors     = '../input/new-lung-vectors/'\n",
    "path_embeddings1 = '../input/embedding/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se cargan los datos de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = []\n",
    "print(\"path: \" + path_vectors)\n",
    "with open(path_vectors + \"sentences_test.txt\", \"rb\") as fp:\n",
    "    test_sentences = pickle.load(fp)\n",
    "\n",
    "print(test_sentences[0])\n",
    "\n",
    "## ********** Oraciones ********** ##\n",
    "word2idx = np.load(path_vectors + 'word2index.npy', allow_pickle=True).item()\n",
    "tag2idx  = np.load(path_vectors + 'tag2index.npy', allow_pickle=True).item()\n",
    "idx2tag  = np.load(path_vectors + 'index2tag.npy', allow_pickle=True).item()\n",
    "\n",
    "X_train = np.load(path_vectors + 'X_train.npy')\n",
    "X_test  = np.load(path_vectors + 'X_test.npy')\n",
    "X_dev   = np.load(path_vectors + 'X_dev.npy')\n",
    "\n",
    "y_train  = np.load(path_vectors + 'y_train.npy')\n",
    "y_test   = np.load(path_vectors + 'y_test.npy')\n",
    "y_dev    = np.load(path_vectors + 'y_dev.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas de carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('**** Diccionario de palabras: ****\\n')\n",
    "#for key, value in word2idx.items():\n",
    "#    if value == 10:\n",
    "#        break\n",
    "#    else:\n",
    "#        print(key, ' : ', value)\n",
    "        \n",
    "#print(X_train[0])\n",
    "#print(len(X_train))\n",
    "\n",
    "#print(y_train[0])\n",
    "print(len(y_train))\n",
    "#print(len(y_test))\n",
    "#print(len(y_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se carga el embedding de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = path_embeddings1 + 'ScieloWiki_cbow_cased.vec'\n",
    "#file2 ='../input/new-lung-vectors/char_embedding_lung.txt'\n",
    "file2 = '../input/new-lung-vectors/char_embedding_new.txt'\n",
    "embedding_matrix = np.concatenate([bme(file1, NUM_WORDS, EMBED_DIM, word2idx),\n",
    "                                   bme(file2, NUM_WORDS, CHAR_EMBEDD, word2idx)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definici√≥n del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "#with strategy.scope():\n",
    "# Input Layer\n",
    "input1 = Input(shape=(LEN_SENTS,), dtype='int32')\n",
    "\n",
    "# Embedding Layer\n",
    "sentences = Embedding(NUM_WORDS,\n",
    "                    EMBED_DIM + CHAR_EMBEDD,\n",
    "                    input_length=LEN_SENTS,  \n",
    "                    weights=[embedding_matrix],\n",
    "                    trainable=False,\n",
    "                    mask_zero=True)(input1)\n",
    "\n",
    "# BI-LSTM Layer\n",
    "myModel = Bidirectional(LSTM(EMBED_DIM + CHAR_EMBEDD, \n",
    "                             return_sequences=True\n",
    "                            ),\n",
    "                        name='bilstm1')(sentences)\n",
    "\n",
    "# TimeDistributed Layer\n",
    "myModel  = TimeDistributed(Dropout(_DROPOUT))(myModel)\n",
    "myModel  = TimeDistributed(Dense(units=(EMBED_DIM + CHAR_EMBEDD)*2, activation='relu'))(myModel)\n",
    "myModel  = TimeDistributed(Dense(units=NUM_TAGS, activation='relu'))(myModel)\n",
    "\n",
    "# CRF Layer\n",
    "crf= crf4(NUM_TAGS, sparse_target=True, name='crf_layer')\n",
    "\n",
    "merged_chain = crf(myModel)\n",
    "\n",
    "model = Model(inputs=input1, outputs=merged_chain)\n",
    "\n",
    "model.compile(optimizer='Nadam', loss=crf.loss, metrics=[crf.accuracy])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entranamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Fit the best model\n",
    "history = model.fit(X_train, y_train, \n",
    "                      validation_data  = (X_dev, y_dev),\n",
    "                      batch_size       = _BACH_SIZE, \n",
    "                      epochs           = _EPOCHS,\n",
    "                      verbose          = 1, \n",
    "                      callbacks        = [tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### se almacena el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(save_dir + \"/\" + MODEL + \".json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(save_dir + \"/\" + MODEL + \".h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluamos el modelo y calculamos el valor de precision con respecto a los datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test[0][0], \"\\n\")\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_test, y_test)\n",
    "print(f\"{model.metrics_names[1]}: {scores[1] * 100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Procedemos a Graficar el comportamiento del Entrenamiento, tanto del conjunto de entrenamiento como el de validaci√≥n con respecto a la cantidad de epocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_performance(\n",
    "    train_loss     = history.history.get('loss', []),\n",
    "    train_acc      = history.history.get('viterbi_accuracy', []),\n",
    "    train_val_loss = history.history.get('val_loss', []),\n",
    "    train_val_acc  = history.history.get('val_viterbi_accuracy', [])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hacemos la prediccion sobre el conjunto de pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(idx2tag[6])\n",
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logits_to_tokens(np.argmax(prediction, -1), idx2tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred[0], \"\\n\")\n",
    "print(test_sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hallamos los valores de F1 score, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "for i, oracion in enumerate(test_sentences):\n",
    "    row_sent = []\n",
    " \n",
    "    for j, lista_palabras in enumerate(oracion):\n",
    "        row_sent.append(lista_palabras[1])\n",
    "\n",
    "    qekk = ['-PAD-'] * LEN_SENTS\n",
    "\n",
    "    qekk[:len(row_sent)] = row_sent\n",
    "    y_true.append(qekk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prub = np.argmax(y_test, axis=-1)\n",
    "print(idx2tag)\n",
    "#print(prub[0])\n",
    "#print(y_true[0])\n",
    "#print(len(y_true))\n",
    "#print(len(y_true[0]))\n",
    "#print(len(y_true[1]), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li1 = sum(y_true, [])\n",
    "li2 = sum(y_pred, [])\n",
    "\n",
    "results = pd.DataFrame(columns=['Expected', 'Predicted'])\n",
    "\n",
    "results['Expected'] = li1\n",
    "results['Predicted'] = li2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#hh1 = seqclarep(results['Expected'], results['Predicted'])\n",
    "#print('\\nclassification_report:\\n', hh1)\n",
    "\n",
    "\n",
    "print(\"precision: {:.1%}\".format(precision_score(y_true, y_pred)))\n",
    "print(\"   recall: {:.1%}\".format(recall_score(y_true,    y_pred)))\n",
    "print(\" accuracy: {:.1%}\".format(accuracy_score(y_true,  y_pred)))\n",
    "print(\" F1-score: {:.1%}\".format(f1_score(y_true,        y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hallamos el calculo de cada una de las etiquetas por separado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = eskclarep(results['Expected'], results['Predicted'])\n",
    "print(report_to_df(report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = {'y_Actual':    results['Expected'],\n",
    "        'y_Predicted': results['Predicted']\n",
    "        }\n",
    "\n",
    "df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'], margins = True)\n",
    "\n",
    "sn.heatmap(confusion_matrix, annot=True)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "### Creamos un peque√±o Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_samples = [\n",
    "    \"CICLO 2 CARBOPLATINO / PACLITAXEL . \".split(),\n",
    "    \"En Agosto de 2015 ha recibido 3 ciclos de CISPLATINO / VINORELBINA buena tolerancia clinica .\".split(),\n",
    "    \"QT : CISPLATINO 75 mg / m2 DIA 1 IV + VINORELBINA 25 mg / m2¬†IV DIAS 1,8 - Adenocarcinoma pulmon lobulo superior derecho \".split(),\n",
    "    \"El dia 27 de junio iniciamos tratamiento con quimioterapia segun esquema CARBOPLATINO / PEMETREXED .\".split(),\n",
    "    \"CICLO 1 CARBOPLATINO AUC 5 - PEMETREXED 500 mg/m2 IV cada 21 dias..\".split(),\n",
    "    \"RT con dosis¬†50 Gy, se encuentra bien. .\".split(),\n",
    "    \"Carcinoma escamoso de pulm√≥n cT3 cN2 cM0 (al menos estadio IIIB de TNM 8¬™ ed .\".split(),\n",
    "    \"Diagnosticado en marzo de 2016 de Adenoca de pulm√≥n cT2cN2cM1a .\".split(),\n",
    "    \"Ha sido diagnosticada de cancer de pulmon en marzo de 2019 .\".split(),\n",
    "    \"Inicia tratamiento con Cisplatino + Pemetrexed + Bevacizumab (5 ciclos administrados, ultimo en enero de 2014).\".split(),\n",
    "    \"Carcinoma escamoso de pulm√≥n intervenido en marzo 2017 .\".split(),\n",
    "    \"En 2014, intervenido de carcinoma de pulm√≥n pT2bN1cM0 realizandose nefrectomia derecha .\".split(),\n",
    "    \"carcinoma microcitico de pulmon t4 n2 m0 en tto quimioterapico: carboplatino / etoposido .\".split(),\n",
    "    \"Colico renoureteral derecho con fracaso renal obstructivo en Julio de 2015 . \".split()\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Ner: \\n\", ner_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertimos las Entradas del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_samples_X    = []\n",
    "\n",
    "for s1 in ner_samples:\n",
    "    s1_int = []\n",
    "    for w in s1:\n",
    "        try:\n",
    "            s1_int.append(word2idx[w.lower()])\n",
    "        except KeyError:\n",
    "            s1_int.append(word2idx['-OOV-'])\n",
    "    ner_samples_X.append(s1_int)\n",
    "\n",
    "ner_samples_X = pad_sequences(ner_samples_X, maxlen=LEN_SENTS, padding='post')\n",
    "\n",
    "\n",
    "print(\"Examples: \\n\", ner_samples_X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se ejecuta la predici√≥n con la entrada de ejemplo en el modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = model.predict(ner_samples_X)\n",
    "#predictions2 = model.predict(uncertainty_samples_X)\n",
    "#predictions3 = model.predict(both_samples_X)\n",
    "\n",
    "print(\"Examples: \\n\", predictions1, predictions1.shape)\n",
    "#print(\"\\nUncertainty: \\n\",predictions2, predictions2.shape)\n",
    "#print(predictions3, predictions3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversi√≥n de la salida del modelo a un lista de indices de tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_tokens1 = logits_to_tokens(np.argmax(predictions1, -1), idx2tag)\n",
    "#log_tokens2 = logits_to_tokens(np.argmax(predictions2, -1), idx2tag)\n",
    "#log_tokens3 = logits_to_tokens(np.argmax(predictions3, -1), idx2tag)\n",
    "\n",
    "\n",
    "print(\"Ner: \\n\", log_tokens1[0])\n",
    "#print(\"\\nUncertainty: \\n\", log_tokens2[0])\n",
    "#print(\"\\nBoth: \\n\", log_tokens3[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultado de Ner: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h, oracc in enumerate(ner_samples):\n",
    "    heads = oracc\n",
    "    body  = [log_tokens1[h][:len(oracc)]]\n",
    "    display(HTML(\"<div style='overflow-x: auto; white-space: nowrap;'>\" + \n",
    "                 tabulate(body, headers=heads, tablefmt=\"html\") + \n",
    "                 \"</div>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
